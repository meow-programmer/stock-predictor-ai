import numpy as np
import pandas as pd
import os
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf

Sequential = tf.keras.models.Sequential
LSTM = tf.keras.layers.LSTM
Dense = tf.keras.layers.Dense
Dropout = tf.keras.layers.Dropout


# ==== Path Setup ====
symbol = input("Enter stock symbol: ").upper()
base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
file_path = os.path.join(base_dir, 'data', 'cleaned', f'{stock_symbol}.xlsx')

# Reading the data
df = pd.read_excel(file_path)
print("Columns in dataset:", df.columns.tolist())


# Map actual dataset columns
close_col = f"Close_{symbol}"
high_col = f"High_{symbol}"
low_col = f"Low_{symbol}"
open_col = f"Open_{symbol}"
volume_col = f"Volume_{symbol}"

# Now define features correctly
features = [close_col, high_col, low_col, open_col, volume_col]

# Keep only these columns
df = df[features]



# ==== Feature Engineering ====
# 1. SMA
df['SMA_5'] = df[close_col].rolling(window=5).mean()
df['SMA_30'] = df[close_col].rolling(window=30).mean()
df['SMA_50'] = df[close_col].rolling(window=50).mean()

# 2. EMA
df['EMA_12'] = df[close_col].ewm(span=12, adjust=False).mean()
df['EMA_26'] = df[close_col].ewm(span=26, adjust=False).mean()

# 3. RSI
delta = df[close_col].diff()
gain = delta.where(delta > 0, 0)
loss = -delta.where(delta < 0, 0)

avg_gain = gain.rolling(window=14).mean()
avg_loss = loss.rolling(window=14).mean()

rs = avg_gain / avg_loss
df['RSI'] = 100 - (100 / (1 + rs))

# 4. MACD
df['MACD'] = df['EMA_12'] - df['EMA_26']
df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()

# 5. Bollinger Bands
df['20_SMA'] = df[close_col].rolling(window=20).mean()
df['Upper_Band'] = df['20_SMA'] + (df[close_col].rolling(window=20).std() * 2)
df['Lower_Band'] = df['20_SMA'] - (df[close_col].rolling(window=20).std() * 2)

# 6. Volume
df['Volume_MA'] = df[volume_col].rolling(window=30).mean()


# ==== Data Preprocessing ====
# Fill any NaN values generated by rolling operations
df = df.dropna()

# Now we will use all the calculated features for modeling
features = [
    'close_col', 'SMA_5', 'SMA_30', 'SMA_50',
    'EMA_12', 'EMA_26', 'RSI', 'MACD', 'Signal_Line',
    'Upper_Band', 'Lower_Band', 'Volume_MA'
]
df = df[features]
df = df[features]

# Scaling the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df.values)

# ==== Sequence Creation ====
sequence_length = 60  # Using past 60 days to predict the next day
x, y = [], []
for i in range(sequence_length, len(scaled_data)):
    x.append(scaled_data[i - sequence_length:i, :])  # Include all features
    y.append(scaled_data[i, 0])  # Predict the closing price

x = np.array(x)
y = np.array(y)

# Reshaping for LSTM input
x = np.reshape(x, (x.shape[0], x.shape[1], x.shape[2]))

# ==== LSTM Model ====
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(x.shape[1], x.shape[2])))
model.add(Dropout(0.2))

model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))

model.add(Dense(units=25))
model.add(Dense(units=1))

model.compile(optimizer='adam', loss='mean_squared_error')

# ==== Model Training ====
model.fit(x, y, batch_size=32, epochs=25)

# ==== Prediction ====
test_data = scaled_data[-sequence_length:]
x_test = []
x_test.append(test_data)

x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2]))

# Predict scaled closing price
predicted_price_scaled = model.predict(x_test)

# Create a dummy array with same shape as scaler input
dummy = np.zeros((predicted_price_scaled.shape[0], scaled_data.shape[1]))
dummy[:, 0] = predicted_price_scaled[:, 0]  # put prediction in the "Close" column

# Inverse transform
predicted_price = scaler.inverse_transform(dummy)[:, 0]  # only take Close back
print("Predicted Closing Price:", predicted_price[-1])
